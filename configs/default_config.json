{
  "model": {
    "base_model_name": "meta-llama/Llama-2-7b-hf",
    "model_type": "causal_lm",
    "max_length": 2048,
    "torch_dtype": "float16",
    "load_in_4bit": true,
    "device_map": "auto"
  },
  "training": {
    "output_dir": "outputs",
    "lora_r": 8,
    "lora_alpha": 32,
    "lora_dropout": 0.1,
    "learning_rate": 2e-5,
    "num_train_epochs": 3,
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 4,
    "max_grad_norm": 0.3,
    "warmup_ratio": 0.03,
    "use_rslora": false,
    "use_dora": false
  },
  "data": {
    "train_file": "data/train.json",
    "validation_file": "data/validation.json",
    "text_column": "text",
    "max_length": 512,
    "stride": 128
  },
  "agents": {
    "orchestrator": {},
    "data_generator": {},
    "knowledge_retrieval": {},
    "trainer": {},
    "evaluator": {},
    "debugger": {}
  }
}
